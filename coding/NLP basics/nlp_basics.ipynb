{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/srinidhisunkara/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\" Hello Welcome, to Srinidhi's NLP.\n",
    "Please do read all the content I post! to become an expert. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "# Sentence --> paragraphs\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "documents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello Welcome, to Srinidhi's NLP.\n",
      "Please do read all the content I post!\n",
      "to become an expert.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Srinidhi',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'read',\n",
       " 'all',\n",
       " 'the',\n",
       " 'content',\n",
       " 'I',\n",
       " 'post',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'an',\n",
       " 'expert',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paragraph to words\n",
    "# sentence to words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(corpus)\n",
    "\n",
    "#expect 's everthing is seperated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello Welcome, to Srinidhi's NLP.  ['Hello', 'Welcome', ',', 'to', 'Srinidhi', \"'s\", 'NLP', '.']\n",
      "Please do read all the content I post!  ['Please', 'do', 'read', 'all', 'the', 'content', 'I', 'post', '!']\n",
      "to become an expert.  ['to', 'become', 'an', 'expert', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence+\"  \"+str(word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Srinidhi',\n",
       " \"'\",\n",
       " 's',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'read',\n",
       " 'all',\n",
       " 'the',\n",
       " 'content',\n",
       " 'I',\n",
       " 'post',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'an',\n",
       " 'expert',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)\n",
    "\n",
    "# even the 's is seperated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Srinidhi',\n",
       " \"'s\",\n",
       " 'NLP.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'read',\n",
       " 'all',\n",
       " 'the',\n",
       " 'content',\n",
       " 'I',\n",
       " 'post',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'an',\n",
       " 'expert',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)\n",
    "\n",
    "# 's remains the same but . is attached to the lastword expect the last sentences last word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming - Text Preprocessing\n",
    "-- Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reviews ---> eating, eat, eaten - stem word is eat\n",
    "words = [\"eating\", \"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalized---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+stemming.stem(word))\n",
    "## major disadvantage of stemming is for some of the words the form changes and may not get the exact meaning history---->histori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no work case\n",
    "stemming.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working case\n",
    "stemming.stem('sitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexpStemmer class\n",
    "-- with the help of which we can easily implement regular expression stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4) # remove ing or s or e or able is present at the end of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Stemmer \n",
    "-- better than porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowballstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eats------>eat\n",
      "eaten------>eaten\n",
      "writing------>write\n",
      "writes------>write\n",
      "programming------>program\n",
      "programs------>program\n",
      "history------>histori\n",
      "finally------>final\n",
      "finalized------>final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'------>'+snowballstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairli\n",
      "sportingli\n"
     ]
    }
   ],
   "source": [
    "# difference between snowball and porter stemmer\n",
    "print(stemming.stem('fairly'))\n",
    "print(stemming.stem('sportingly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fair\n",
      "sport\n"
     ]
    }
   ],
   "source": [
    "print(snowballstemmer.stem('fairly'))\n",
    "print(snowballstemmer.stem('sportingly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- disadvantage of stemming - for some of the words form change\n",
    "- Lemmitization solves all those problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizer\n",
    "- Output of lemmatization is called lemma or root word rather than stem word\n",
    "- We get valid word , no change in form\n",
    "- It takes more time to run than stemming\n",
    "- Used in Q & A, chatbots, text summerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/srinidhisunkara/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/srinidhisunkara/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going---->n----->going\n",
      "going---->v----->go\n",
      "going---->a----->going\n",
      "going---->r----->going\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "POS \n",
    "Noun - n - default\n",
    "Verb - v\n",
    "Adjective - a\n",
    "Adverb - r\n",
    "'''\n",
    "for pos in ['n','v','a','r']:\n",
    "    print('going'+\"---->\"+pos+\"----->\"+lemmatizer.lemmatize(\"going\", pos=pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eat\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->history\n",
      "finally----->finally\n",
      "finalized----->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----->\"+lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "I have three visions for India.\n",
    "\n",
    "In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. From Alexander onwards, the Greeks, the Portuguese, the British, the French, the Dutch—all of them came and looted us, took over what was ours. Yet, we have not conquered anyone. We have not grabbed their land, culture, and history, nor tried to enforce our way of life on them.\n",
    "\n",
    "Why? Because we respect the freedom of others.\n",
    "\n",
    "That is why my first vision is that of freedom.\n",
    "I believe that India got its first vision of freedom in 1857, when we started the war of independence. It is this freedom that we must protect and nurture if we are to build a self-reliant and developed India.\n",
    "\n",
    "My second vision for India’s development.\n",
    "For fifty years, we have been a developing nation. It is time we see ourselves as a developed nation. We are among the top five nations in the world in terms of GDP. We have ten percent growth rate in most areas. Our poverty levels are falling, our achievements are being recognized worldwide. Yet, we lack the confidence to see ourselves as a developed nation, self-reliant and self-assured.\n",
    "\n",
    "Isn’t this incorrect?\n",
    "\n",
    "I have a third vision.\n",
    "India must stand up to the world. Because I believe that unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
    "\n",
    "I want to ask you, what kind of a nation are we building?\n",
    "There was a time when we were the most advanced and prosperous nation in the world. We had great minds, wealth, and culture. But over the years, we lost confidence, and today, even after so many advancements, we hesitate to call ourselves developed.\n",
    "\n",
    "Why?\n",
    "\n",
    "We are obsessed with foreign things. We want foreign televisions, foreign shirts, foreign technology. Why this obsession? It is self-respect that we are lacking. If we do not respect ourselves, how can we expect others to respect us?\n",
    "\n",
    "I was in Hyderabad giving a lecture when a 14-year-old girl asked me for my autograph. I asked her what her goal in life was. She replied, \"I want to live in a developed India.\"\n",
    "\n",
    "For her, and for all young people, I have this dream:\n",
    "A developed India. An India that is strong. An India that is self-reliant.\n",
    "\n",
    "Let us all work together and make this dream a reality.\n",
    "\n",
    "Jai Hind!\n",
    "'''\n",
    "# words like i the she have - dont play any significant role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/srinidhisunkara/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the stopwords available in the corpus\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nI have three visions for India.',\n",
       " 'In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds.',\n",
       " 'From Alexander onwards, the Greeks, the Portuguese, the British, the French, the Dutch—all of them came and looted us, took over what was ours.',\n",
       " 'Yet, we have not conquered anyone.',\n",
       " 'We have not grabbed their land, culture, and history, nor tried to enforce our way of life on them.',\n",
       " 'Why?',\n",
       " 'Because we respect the freedom of others.',\n",
       " 'That is why my first vision is that of freedom.',\n",
       " 'I believe that India got its first vision of freedom in 1857, when we started the war of independence.',\n",
       " 'It is this freedom that we must protect and nurture if we are to build a self-reliant and developed India.',\n",
       " 'My second vision for India’s development.',\n",
       " 'For fifty years, we have been a developing nation.',\n",
       " 'It is time we see ourselves as a developed nation.',\n",
       " 'We are among the top five nations in the world in terms of GDP.',\n",
       " 'We have ten percent growth rate in most areas.',\n",
       " 'Our poverty levels are falling, our achievements are being recognized worldwide.',\n",
       " 'Yet, we lack the confidence to see ourselves as a developed nation, self-reliant and self-assured.',\n",
       " 'Isn’t this incorrect?',\n",
       " 'I have a third vision.',\n",
       " 'India must stand up to the world.',\n",
       " 'Because I believe that unless India stands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be strong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'I want to ask you, what kind of a nation are we building?',\n",
       " 'There was a time when we were the most advanced and prosperous nation in the world.',\n",
       " 'We had great minds, wealth, and culture.',\n",
       " 'But over the years, we lost confidence, and today, even after so many advancements, we hesitate to call ourselves developed.',\n",
       " 'Why?',\n",
       " 'We are obsessed with foreign things.',\n",
       " 'We want foreign televisions, foreign shirts, foreign technology.',\n",
       " 'Why this obsession?',\n",
       " 'It is self-respect that we are lacking.',\n",
       " 'If we do not respect ourselves, how can we expect others to respect us?',\n",
       " 'I was in Hyderabad giving a lecture when a 14-year-old girl asked me for my autograph.',\n",
       " 'I asked her what her goal in life was.',\n",
       " 'She replied, \"I want to live in a developed India.\"',\n",
       " 'For her, and for all young people, I have this dream:\\nA developed India.',\n",
       " 'An India that is strong.',\n",
       " 'An India that is self-reliant.',\n",
       " 'Let us all work together and make this dream a reality.',\n",
       " 'Jai Hind!']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply stop words filter them and apply stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))] # consider only words that are not stop words and apply stemmer\n",
    "    sentences[i]= ' '.join(words) # convert all the words to sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i three vision india .',\n",
       " 'in 3000 year histori , peopl world come invad us , captur land , conquer mind .',\n",
       " 'from alexand onward , greek , portugues , british , french , dutch—al came loot us , took .',\n",
       " 'yet , conquer anyon .',\n",
       " 'we grab land , cultur , histori , tri enforc way life .',\n",
       " 'whi ?',\n",
       " 'becaus respect freedom other .',\n",
       " 'that first vision freedom .',\n",
       " 'i believ india got first vision freedom 1857 , start war independ .',\n",
       " 'it freedom must protect nurtur build self-reli develop india .',\n",
       " 'my second vision india ’ develop .',\n",
       " 'for fifti year , develop nation .',\n",
       " 'it time see develop nation .',\n",
       " 'we among top five nation world term gdp .',\n",
       " 'we ten percent growth rate area .',\n",
       " 'our poverti level fall , achiev recogn worldwid .',\n",
       " 'yet , lack confid see develop nation , self-reli self-assur .',\n",
       " 'isn ’ incorrect ?',\n",
       " 'i third vision .',\n",
       " 'india must stand world .',\n",
       " 'becaus i believ unless india stand world , one respect us .',\n",
       " 'onli strength respect strength .',\n",
       " 'we must strong militari power also econom power .',\n",
       " 'both must go hand-in-hand .',\n",
       " 'i want ask , kind nation build ?',\n",
       " 'there time advanc prosper nation world .',\n",
       " 'we great mind , wealth , cultur .',\n",
       " 'but year , lost confid , today , even mani advanc , hesit call develop .',\n",
       " 'whi ?',\n",
       " 'we obsess foreign thing .',\n",
       " 'we want foreign televis , foreign shirt , foreign technolog .',\n",
       " 'whi obsess ?',\n",
       " 'it self-respect lack .',\n",
       " 'if respect , expect other respect us ?',\n",
       " 'i hyderabad give lectur 14-year-old girl ask autograph .',\n",
       " 'i ask goal life .',\n",
       " \"she repli , `` i want live develop india . ''\",\n",
       " 'for , young peopl , i dream : a develop india .',\n",
       " 'an india strong .',\n",
       " 'an india self-reli .',\n",
       " 'let us work togeth make dream realiti .',\n",
       " 'jai hind !']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i three vision india .',\n",
       " 'in 3000 year histori , peopl world come invad us , captur land , conquer mind .',\n",
       " 'from alexand onward , greek , portugues , british , french , dutch—al came loot us , took .',\n",
       " 'yet , conquer anyon .',\n",
       " 'we grab land , cultur , histori , tri enforc way life .',\n",
       " 'whi ?',\n",
       " 'becaus respect freedom other .',\n",
       " 'that first vision freedom .',\n",
       " 'i believ india got first vision freedom 1857 , start war independ .',\n",
       " 'it freedom must protect nurtur build self-reli develop india .',\n",
       " 'my second vision india ’ develop .',\n",
       " 'for fifti year , develop nation .',\n",
       " 'it time see develop nation .',\n",
       " 'we among top five nation world term gdp .',\n",
       " 'we ten percent growth rate area .',\n",
       " 'our poverti level fall , achiev recogn worldwid .',\n",
       " 'yet , lack confid see develop nation , self-reli self-assur .',\n",
       " 'isn ’ incorrect ?',\n",
       " 'i third vision .',\n",
       " 'india must stand world .',\n",
       " 'becaus i believ unless india stand world , one respect us .',\n",
       " 'onli strength respect strength .',\n",
       " 'we must strong militari power also econom power .',\n",
       " 'both must go hand-in-hand .',\n",
       " 'i want ask , kind nation build ?',\n",
       " 'there time advanc prosper nation world .',\n",
       " 'we great mind , wealth , cultur .',\n",
       " 'but year , lost confid , today , even mani advanc , hesit call develop .',\n",
       " 'whi ?',\n",
       " 'we obsess foreign thing .',\n",
       " 'we want foreign televis , foreign shirt , foreign technolog .',\n",
       " 'whi obsess ?',\n",
       " 'it self-respect lack .',\n",
       " 'if respect , expect other respect us ?',\n",
       " 'i hyderabad give lectur 14-year-old girl ask autograph .',\n",
       " 'i ask goal life .',\n",
       " \"she repli , `` i want live develop india . ''\",\n",
       " 'for , young peopl , i dream : a develop india .',\n",
       " 'an india strong .',\n",
       " 'an india self-reli .',\n",
       " 'let us work togeth make dream realiti .',\n",
       " 'jai hind !']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## applying snowball stemmer\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "stemmer = SnowballStemmer('english')\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))] # consider only words that are not stop words and apply stemmer\n",
    "    sentences[i]= ' '.join(words) # convert all the words to sentence\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I three visions India .',\n",
       " 'In 3000 years history , people world come invade us , capture land , conquer mind .',\n",
       " 'From Alexander onwards , Greeks , Portuguese , British , French , Dutch—all come loot us , take .',\n",
       " 'Yet , conquer anyone .',\n",
       " 'We grab land , culture , history , try enforce way life .',\n",
       " 'Why ?',\n",
       " 'Because respect freedom others .',\n",
       " 'That first vision freedom .',\n",
       " 'I believe India get first vision freedom 1857 , start war independence .',\n",
       " 'It freedom must protect nurture build self-reliant develop India .',\n",
       " 'My second vision India ’ development .',\n",
       " 'For fifty years , develop nation .',\n",
       " 'It time see develop nation .',\n",
       " 'We among top five nations world term GDP .',\n",
       " 'We ten percent growth rate areas .',\n",
       " 'Our poverty level fall , achievements recognize worldwide .',\n",
       " 'Yet , lack confidence see develop nation , self-reliant self-assured .',\n",
       " 'Isn ’ incorrect ?',\n",
       " 'I third vision .',\n",
       " 'India must stand world .',\n",
       " 'Because I believe unless India stand world , one respect us .',\n",
       " 'Only strength respect strength .',\n",
       " 'We must strong military power also economic power .',\n",
       " 'Both must go hand-in-hand .',\n",
       " 'I want ask , kind nation build ?',\n",
       " 'There time advance prosperous nation world .',\n",
       " 'We great mind , wealth , culture .',\n",
       " 'But years , lose confidence , today , even many advancements , hesitate call develop .',\n",
       " 'Why ?',\n",
       " 'We obsess foreign things .',\n",
       " 'We want foreign televisions , foreign shirt , foreign technology .',\n",
       " 'Why obsession ?',\n",
       " 'It self-respect lack .',\n",
       " 'If respect , expect others respect us ?',\n",
       " 'I Hyderabad give lecture 14-year-old girl ask autograph .',\n",
       " 'I ask goal life .',\n",
       " \"She reply , `` I want live develop India . ''\",\n",
       " 'For , young people , I dream : A develop India .',\n",
       " 'An India strong .',\n",
       " 'An India self-reliant .',\n",
       " 'Let us work together make dream reality .',\n",
       " 'Jai Hind !']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying lemmatization\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word, pos='v') for word in words if word not in set(stopwords.words('english'))] # consider only words that are not stop words and apply stemmer\n",
    "    sentences[i]= ' '.join(words) # convert all the words to sentence\n",
    "sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
